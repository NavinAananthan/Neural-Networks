{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM2dFRPssuDx"
      },
      "source": [
        "**Neural Networks**\n",
        "\n",
        "This exercise is based how neural networks works and what are the function used in it to predict and optimize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy-2GOTusq78"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image,ImageOps\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmOA3vwkkNGa"
      },
      "outputs": [],
      "source": [
        "model=keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
        "model.compile(optimizer='sgd',loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQcVbipykb3-"
      },
      "outputs": [],
      "source": [
        "x=np.array([-1.0,0.0,1.0,2.0,3.0,4.0])\n",
        "y=np.array([-3.0,-1.0,1.0,3.0,5.0,7.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sWypFUpkth4"
      },
      "outputs": [],
      "source": [
        "model.fit(x,y,epochs=10)\n",
        "print(model.predict([10.0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCfI9yhr9Rb"
      },
      "source": [
        "**Loading Image DataSet**\n",
        "\n",
        "In this we will see on how to load image dataset from tensorflow and use them predict it .\n",
        "\n",
        "We then create a neural network model and use it for predicting the minst fashion data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYl5PzBLkvB1"
      },
      "outputs": [],
      "source": [
        "# Loading the fashion mnist dataset\n",
        "fashion_data=tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(train_images,train_labels),(test_images,test_labels)=fashion_data.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBOKe7Pt0uc"
      },
      "outputs": [],
      "source": [
        "# Coding the layers\n",
        "\n",
        "# Preprocessing the image (Normalizing the values to the range)\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28, 1)), # The size of the image 28x28 pixels\n",
        "    keras.layers.Dense(units=128,activation=tf.nn.relu), # There are 128 units inside\n",
        "    keras.layers.Dense(units=10,activation=tf.nn.softmax) # The output is for classifying 10 so we give units as 10\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yau-mJ76ajo"
      },
      "outputs": [],
      "source": [
        "#This function is to compile the model with best parameters \n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "#Fitting the model with the given training images and the corresponding labels\n",
        "hist=model.fit(train_images,train_labels,epochs=40)\n",
        "\n",
        "#Evaluating the model on how best it give for training and testing data test\n",
        "model.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuBVru3rohHz"
      },
      "source": [
        "**Implementing Convolution Layers**\n",
        "\n",
        "We perform convolution with the group of pixels which enhances the image which we have already studied in Computer Vision and Image Analysis for e.g. we take a 3x3 pixel matrix from the given image and we convolute with sobel operator mask of 3x3 which we get a enhanced image.\n",
        "\n",
        "This is mainly done to make computationally faster and reduce the size of the image.\n",
        "\n",
        "**Pooling**\n",
        "\n",
        "In this we choose the max value and place it in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Sg8hqqaoYj0"
      },
      "outputs": [],
      "source": [
        "model1=keras.Sequential([\n",
        "    keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)), # Performing the convolution\n",
        "    keras.layers.MaxPool2D(2,2),                                           # Performing the pooling\n",
        "    keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPool2D(2,2),\n",
        "    keras.layers.Flatten(input_shape=(28,28)), # The size of the image 28x28 pixels\n",
        "    keras.layers.Dense(units=128,activation=tf.nn.relu), # There are 128 units inside\n",
        "    keras.layers.Dense(units=10,activation=tf.nn.softmax) # The output is for classifying 10 so we give units as 10\n",
        "])\n",
        "\n",
        "\n",
        "# to get the summary of the sequential layer \n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13CwpE3WouHy"
      },
      "outputs": [],
      "source": [
        "#This function is to compile the model with best parameters \n",
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "#Fitting the model with the given training images and the corresponding labels\n",
        "hist1=model1.fit(train_images,train_labels,epochs=20)\n",
        "\n",
        "#Evaluating the model on how best it give for training and testing data test\n",
        "model1.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eHas534V5Ol"
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "plt.plot(hist.history['loss'], 'b-', label='train loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'], 'b-', label='train accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ab8uZTzzBuu",
        "outputId": "6b11b757-ea1a-488c-ee38-0063303462b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "\n",
            "probability values of classifying particular image: \n",
            "[1.53049386e-05 8.23071266e-13 9.99972880e-01 6.72911097e-17\n",
            " 6.47629221e-08 1.85831981e-14 1.16955325e-05 2.71469097e-18\n",
            " 4.64854110e-12 3.09996559e-19]\n",
            "\n",
            "The predicted Image belongs to the label 2\n",
            "The Actual Output of the image belongs to label:  2\n"
          ]
        }
      ],
      "source": [
        "# Predicting the outputs for Test images\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "prob_values=classifications[20]\n",
        "print(\"\\nprobability values of classifying particular image: \")\n",
        "print(prob_values)\n",
        "\n",
        "# We find the max probability value among the list to which the image image belongs to \n",
        "prob_values=prob_values.tolist()\n",
        "print(\"\\nThe predicted Image belongs to the label {val}\".format(val=(prob_values.index(max(prob_values)))))\n",
        "print(\"The Actual Output of the image belongs to label: \",test_labels[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byJU3enTjpPJ"
      },
      "outputs": [],
      "source": [
        "# This is to predict the image from downloaded image\n",
        "#bag=Image.open('download.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "#bag=ImageOps.grayscale(bag)\n",
        "\n",
        "#print(bag.size)\n",
        "\n",
        "#arr=np.asarray(bag)\n",
        "#arr=arr/255.0\n",
        "\n",
        "\n",
        "\n",
        "# This is to predict single image in the MNIST dataset\n",
        "img=test_images[10]\n",
        "prob=model.predict(img)\n",
        "print(prob)\n",
        "print(max(prob[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMK6BJ8iQPxo"
      },
      "outputs": [],
      "source": [
        "\n",
        "arr=test_images[3]\n",
        "arr=arr*255.0\n",
        "\n",
        "img=Image.fromarray(arr)\n",
        "img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEsUI5EcTSmu"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img, interpolation='nearest')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}